{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_dir = 'cifar-10-batches-py/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file,'rb') as f:\n",
    "        cifar_dict = pickle.load(f,encoding='bytes')\n",
    "     \n",
    "    return cifar_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['batches.meta','data_batch_1','data_batch_2','test_batch','data_batch_4','data_batch_5','test_batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,direc in zip(all_data,dirs):\n",
    "    all_data[i] = unpickle(cifar_dir+direc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_meta = all_data[0]\n",
    "data_batch_1 = all_data[1]\n",
    "data_batch_2 = all_data[2]\n",
    "#data_batch_3 = all_data[3]\n",
    "#data_batch_4 = all_data[4]\n",
    "#data_batch_5 = all_data[5]\n",
    "test_batch = all_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_batch_1[b'data']\n",
    "X = X.reshape(10000,3,32,32).transpose(0,2,3,1).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f12eece1940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(X[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar_model():\n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        self.data_batches = [data_batch_1,data_batch_2,data_batch_3,data_batch_4,data_batch_5]\n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "        self.test_batch = [test_batch]\n",
    "       \n",
    "    \n",
    "    def set_up_images(self):\n",
    "        print(\"Setting up training images and labels\")\n",
    "        self.training_images = np.vstack(d[b'data'] for d in self.data_batches)\n",
    "        self.training_labels = one_hot_encode(np.hstack(d[b'labels'] for d in self.data_batches),10)\n",
    "        training_len = len(self.training_images)\n",
    "        self.training_images = self.training_images.reshape(training_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        \n",
    "        \n",
    "        print(\"Setting up testing images and labels\")\n",
    "        self.test_images = np.vstack(d[b'data'] for d in self.test_batch)\n",
    "        self.test_labels = one_hot_encode(np.hstack(d[b'labels'] for d in self.test_batch),10)\n",
    "        testing_len = len(self.test_images)\n",
    "        self.test_images = self.test_images.reshape(testing_len,3,32,32).transpose(0,2,3,1)/255\n",
    "        \n",
    "       \n",
    "    def next_batch(self,batch_size):\n",
    "        x = self.training_images[self.i:self.i+batch_size].reshape(batch_size,32,32,3)\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec,vals):\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n,vals))\n",
    "    out[range(n),vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_batch_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2e0398c8eec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCifar_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_up_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c7a5e5deb97b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_batch_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_batch_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_batch_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_batch_4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_batch_5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_batch_3' is not defined"
     ]
    }
   ],
   "source": [
    "ch = Cifar_model()\n",
    "ch.set_up_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,32,32,3])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,10])\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1 = convolutional_layer(x,shape=[4,4,3,32])\n",
    "conv_1_pool = max_pool_2by2(conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2 = convolutional_layer(conv_1_pool,shape=[4,4,32,64])\n",
    "conv_2_pool = max_pool_2by2(conv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "conv_3 = convolutional_layer(conv_2_pool,shape=[2,2,32,64])\n",
    "conv_3_pool = max_pool_2by2(conv_3)\n",
    "conv_3_drop=tf.nn.dropout(conv_3_pool,keep_prob=hold_prob)\n",
    "\n",
    "conv_3_drop.get_shape().as_list()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2_flat = tf.reshape(conv_2_pool,[-1,8*8*64])#tf.reshape(conv_3_pool,[-1,1024])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_layer_1 = tf.nn.relu(normal_full_layer(conv_2_flat,128))\n",
    "affine_layer_1.get_shape().as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "affine_layer_2 = tf.nn.relu(normal_full_layer(affine_layer_1,128))\n",
    "affine_layer_2.get_shape().as_list()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_out = tf.nn.dropout(affine_layer_1,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(drop_out,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.train.AdamOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optim.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 100\n",
    "ch.training_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    num_batches = ch.training_images.shape[0] // batch_size\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            batch = ch.next_batch(batch_size)\n",
    "            sess.run(train, feed_dict={x:batch[0],y_true:batch[1],hold_prob:0.25})\n",
    "       \n",
    "            if i%100 == 0:\n",
    "                print(\"Currently on step : {}\".format(i))\n",
    "                print(\"Accuracy is :\")\n",
    "                matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "                #matches = [True,False,True,True,.......]\n",
    "                acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "                print(sess.run(acc,feed_dict={x:ch.test_images,y_true:ch.test_labels,hold_prob:1.0}))\n",
    "                print(\"\\n\")\n",
    "       \n",
    "    saver.save(sess,\"./cifar_10_train_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "test_path = 'test1.jpeg'\n",
    "test_image1 = cv2.imread(test_path)\n",
    "test_image1=cv2.cvtColor(test_image1, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess = tf.train.Saver().restore(\"./cifar_10_train_model\")\n",
    "    pred = sess.run(y_pred,feed_dict={x:test_image1,hold_prob:1.0})\n",
    "   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
